{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIU-4qp4OIMh"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import librosa\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBIa5k07fcfv"
   },
   "source": [
    "# **SVM Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XctZ2_xTNjaV"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_train_new.csv')\n",
    "data = data.drop(['filename'],axis=1)\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(genre_list)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "\n",
    "data = pd.read_csv('dataset_dev_new.csv')\n",
    "data = data.drop(['filename'],axis=1)\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y_dev = encoder.fit_transform(genre_list)\n",
    "scaler = StandardScaler()\n",
    "X_dev = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "\n",
    "data = pd.read_csv('dataset_eval_new.csv')\n",
    "data = data.drop(['filename'],axis=1)\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y_eval = encoder.fit_transform(genre_list)\n",
    "scaler = StandardScaler()\n",
    "X_eval = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ou3JpwX0OKjJ",
    "outputId": "0ef4dc3b-60b7-44bf-f12d-d4f967c06bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "Accuracy: 0.8535729037587774\n",
      "\n",
      "Eval\n",
      "Accuracy: 0.8196755994358251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_dev)\n",
    "print('Dev')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_dev, y_pred))\n",
    "print()\n",
    "y_pred = clf.predict(X_eval)\n",
    "print('Eval')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byfpOGLZfi-K"
   },
   "source": [
    "# **CNN Approaches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXe1SnZrPv4Y"
   },
   "outputs": [],
   "source": [
    "def small_cnn(input_shape = (256, 256, 1), lr = 1e-3, factor = 16):\n",
    "    img_input = layers.Input(input_shape)\n",
    "    X = layers.Conv2D(factor, 3, padding = 'same', activation = 'relu')(img_input)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Conv2D(factor*2, 3, padding = 'same', activation = 'relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Conv2D(factor*4, 3, padding = 'same', activation = 'relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Conv2D(factor*8, 3, padding = 'same', activation = 'relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Conv2D(factor*16, 3, padding = 'same', activation = 'relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size = (2, 2))(X)\n",
    "    X = layers.Flatten()(X)\n",
    "    X = layers.Dense(128, activation = 'relu')(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.Dense(1)(X)\n",
    "    X = layers.Activation('sigmoid', dtype='float32', name='predictions')(X)\n",
    "    model = models.Model(inputs = img_input, outputs = X)\n",
    "    model.compile(optimizer = Adam(lr), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "EUz9VsT9O7gk",
    "outputId": "b16c6efa-fb4b-4d26-87a5-6ee7723d44a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4816 images belonging to 2 classes.\n",
      "Found 14090 images belonging to 2 classes.\n",
      "\n",
      "Model: mel_spec_model.h5\n",
      "Development Set:\n",
      "Loss: 0.0501\n",
      "Accuracy: 0.9817\n",
      "Evaluation Set:\n",
      "Loss: 0.3875\n",
      "Accuracy:  0.8914\n",
      "\n",
      "Found 4842 images belonging to 2 classes.\n",
      "Found 14180 images belonging to 2 classes.\n",
      "\n",
      "Model: amp_plot_model.h5\n",
      "Development Set:\n",
      "Loss: 0.3834\n",
      "Accuracy: 0.8088\n",
      "Evaluation Set:\n",
      "Loss: 0.3431\n",
      "Accuracy:  0.8434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset,modelpath in zip(['mel_spec_256_crop_first','amp_plot_256_crop_first_negative',],['mel_spec_model.h5','amp_plot_model.h5']):\n",
    "    batch_size = 64\n",
    "    target_size = (256, 256)\n",
    "    color_mode = 'grayscale'\n",
    "    val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    val_generator = val_datagen.flow_from_directory(f'{dataset}/dev/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    test_generator = test_datagen.flow_from_directory(f'{dataset}/eval/', target_size=target_size, batch_size=batch_size, class_mode='binary', color_mode=color_mode, classes = ['real','fake'])\n",
    "    print()\n",
    "    model = small_cnn()\n",
    "    model.load_weights(modelpath)\n",
    "    print(f'Model: {modelpath}')\n",
    "    results = model.evaluate(val_generator,steps=2*len(val_generator),verbose=0)\n",
    "    print('Development Set:')\n",
    "    print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]:.4f}')\n",
    "    results = model.evaluate(test_generator,steps=2*len(test_generator),verbose=0)\n",
    "    print('Evaluation Set:')\n",
    "    print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]: .4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN7ZuW8Afpko"
   },
   "source": [
    "# **LSTM Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQJKFp0MYNGL"
   },
   "outputs": [],
   "source": [
    "dataset = 'npys_32000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LL9J1C7EPoR-"
   },
   "outputs": [],
   "source": [
    "def get_input(filepath):\n",
    "    clip = np.load(filepath)\n",
    "    sample_rate = 16000\n",
    "    rmse = librosa.feature.rms(y=clip)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=clip, sr=sample_rate)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=clip, sr=sample_rate)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=clip, sr=sample_rate)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=clip, sr=sample_rate)\n",
    "    zcr = librosa.feature.zero_crossing_rate(clip)\n",
    "    mfcc = librosa.feature.mfcc(y=clip, sr=sample_rate)\n",
    "    arr = np.concatenate([rmse,chroma_stft,spec_cent,spec_bw,rolloff,zcr,mfcc],axis=0).T\n",
    "    arr = (arr - arr.mean(axis=0))/(arr.std(axis=0))\n",
    "    return [arr]\n",
    "\n",
    "def data_generator(dataset, split = 'train', batch_size = 8):\n",
    "\n",
    "    assert batch_size % 2 == 0\n",
    "    real_files = [f'{dataset}/{split}/real/{f}' for f in os.listdir(f'{dataset}/{split}/real') if '.ipynb' not in f]\n",
    "    fake_files = [f'{dataset}/{split}/fake/{f}' for f in os.listdir(f'{dataset}/{split}/fake') if '.ipynb' not in f]\n",
    "\n",
    "    while True:\n",
    "        real_batch_paths = np.random.choice(a = real_files, size = batch_size // 2)\n",
    "        fake_batch_paths = np.random.choice(a = fake_files, size = batch_size // 2)\n",
    "        batch_input  = []\n",
    "        batch_output = []\n",
    "\n",
    "        for real_input_path, fake_input_path in zip(real_batch_paths, fake_batch_paths):\n",
    "            batch_input += get_input(real_input_path)\n",
    "            batch_input += get_input(fake_input_path)\n",
    "            batch_output += [[0.],[1.]]\n",
    "        # Return a tuple of (input, output) to feed the network\n",
    "        batch_x = np.array(batch_input,dtype=np.float32)\n",
    "        batch_y = np.array(batch_output,dtype=np.float32)\n",
    "\n",
    "        yield(batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVKOSFa6Qk-r"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dev_gen = data_generator(dataset, 'dev', batch_size = batch_size)\n",
    "eval_gen = data_generator(dataset, 'eval', batch_size = batch_size)\n",
    "dev_spe = len(os.listdir(f'{dataset}/dev/real'))//batch_size\n",
    "eval_spe = len(os.listdir(f'{dataset}/eval/real'))//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUBqIeV8Rkoe"
   },
   "outputs": [],
   "source": [
    "def lstm(input_shape = (None, 37), lr = 1e-3):\n",
    "    inputs = layers.Input(input_shape)\n",
    "    X = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "    X = layers.LSTM(64, return_sequences=True)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.LSTM(128, return_sequences=True)(X)\n",
    "    X = layers.LSTM(128, return_sequences=True)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.LSTM(256, return_sequences=False)(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.Dense(128, activation = 'relu')(X)\n",
    "    X = layers.Dropout(rate=0.5)(X)\n",
    "    X = layers.Dense(1)(X)\n",
    "    X = layers.Activation('sigmoid', dtype='float32', name='predictions')(X)\n",
    "    #X = layers.Dense(1, activation = 'sigmoid')(X)\n",
    "    model = models.Model(inputs = inputs, outputs = X)\n",
    "    model.compile(optimizer = Adam(lr), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZ5ZskRPRaH6"
   },
   "outputs": [],
   "source": [
    "model = lstm()\n",
    "model.load_weights('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "5FhMzIT_R7mT",
    "outputId": "b843a2db-f83c-45ac-bb74-151406bdef9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Set:\n",
      "Loss: 0.3529\n",
      "Accuracy: 0.8758\n",
      "Evaluation Set:\n",
      "Loss: 0.5216\n",
      "Accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(dev_gen, verbose = 0, steps = 2*dev_spe)\n",
    "print('Development Set:')\n",
    "print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]:.4f}')\n",
    "results = model.evaluate(eval_gen, verbose = 0, steps = 2*eval_spe)\n",
    "print('Evaluation Set:')\n",
    "print(f'Loss: {results[0]:.4f}\\nAccuracy: {results[1]:.4f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ASV_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
